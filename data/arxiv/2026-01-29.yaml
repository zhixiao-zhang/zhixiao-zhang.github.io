title: Memory Safety / PL / Systems Radar
description: Recent arXiv papers filtered by my interests in systems security, PL,
  and memory safety.
generated_at: '2026-01-29T14:01:47.531397+00:00'
papers:
- arxiv_id: 2601.18944v2
  title: 'Neural Theorem Proving for Verification Conditions: A Real-World Benchmark'
  authors:
  - Qiyuan Xu
  - Xiaokun Luan
  - Renxi Wang
  - Joshua Ong Jun Leang
  - Peixin Wang
  - Haonan Li
  - Wenda Li
  - Conrad Watt
  summary: 'Theorem proving is fundamental to program verification, where the automated
    proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world
    program verification frequently encounters hard VCs that existing Automated Theorem
    Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs
    that burden practical application. While Neural Theorem Proving (NTP) has achieved
    significant success in mathematical competitions, demonstrating the potential
    of machine learning approaches to formal reasoning, its application to program
    verification--particularly VC proving--remains largely unexplored. Despite existing
    work on annotation synthesis and verification-related theorem proving, no benchmark
    has specifically targeted this fundamental bottleneck: automated VC proving. This
    work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting
    the first real-world multi-language benchmark for this task. From real-world projects
    such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines
    (Why3 and Frama-C) to generate semantically equivalent test cases across formal
    languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs),
    both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results
    indicate that although LLMs show promise in VC proving, significant challenges
    remain for program verification, highlighting a large gap and opportunity for
    future research.'
  tldr: '- The problem is that real-world program verification often produces verification
    conditions too difficult for current automated theorem provers, forcing developers
    to write manual proofs and slowing down practical verification efforts.

    - The core method is creating a multi-language benchmark (NTP4VC) from verification
    conditions extracted via industrial tools from actual OS kernels, then testing
    both general and fine-tuned large language models on their ability to prove these
    conditions.

    - This matters because it directly measures and pushes progress on automating
    a critical bottleneck in software verification, which is essential for building
    memory-safe and secure low-level systems like kernels without prohibitive manual
    effort.'
  ai_score: 8
  ai_reason: The paper directly addresses automated theorem proving for verification
    conditions, a core bottleneck in program verification, which is highly relevant
    to formal semantics, program analysis, and verification techniques like those
    used in Rust and sanitizers.
  updated: '2026-01-28T18:25:21Z'
  published: '2026-01-26T20:37:11Z'
  pdf_url: https://arxiv.org/pdf/2601.18944v2
  primary_category: cs.AI
  categories:
  - cs.AI
  - cs.PL
  - cs.SE
